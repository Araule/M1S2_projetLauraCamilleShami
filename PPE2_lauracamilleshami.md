# Programmation et Projet EncadrÃ© 2

Objectif : RepÃ©rer les sujets et les expressions qui ont fait lâ€™actualitÃ© en 2022 dans les publications de Le Monde

<br>

## I. Les scripts

### A. Comment les scripts s'appellent les uns les autres


#### partie 1 : filtres et choix donnÃ©es
```mermaid
flowchart LR
  
  x{terminal} -- "on lance le fichier" --> t[execute_scripts.sh]
  t -- "on suit les questions pour choisir les filtres" --> a[extract_corpus.py]
  t -- "on choisit la forme des tokens Ã  traiter, le nombre de sujets Ã  traiter et l'affichage des rÃ©sultats" --> f[run_lda.py]

```

#### partie 2 : script `extract_corpus.py` - extraction du sous-corpus
```mermaid
flowchart TB

  t{execute_scripts.sh} ----> a[extract_corpus.py]
  a -- "appelle" --> b1(script:get_corpus.py, fonction:get_Corpus)

  subgraph "crÃ©ation de l'instance Corpus grÃ¢ce au fichier datastructures.py"
    b1 -- "appelle" --> b2(script:get_corpus.py, fonction:get_Article)
    b2 -- "appelle en boucle" --> c(script:get_articles.py, fonction:to_article, which_analyse)

    subgraph "tokenisation et pos-tagging"
      direction LR
      c -- "appelle" --> d(script:get_analyse.py, fonctions:get_stanza, get_trankit ou get_spacy)
      d -- "renvoie une liste d'instances de Token" --> c
    end

    c -- "renvoie une instance de Article" --> b2
    b2 -- "renvoie une liste d'instances de Article" --> b1
  end

  b1 -- "renvoie une instance de Corpus" --> a

```

#### partie 3 : suite du script `extract_corpus.py` - crÃ©ation du fichier selon le format de sortie
```mermaid
flowchart LR

  p{partie 2} ----> a[extract_corpus.py]
  a -- "appelle" --> b(script:get_xml.py, fonction:to_xml) ----> e(crÃ©ation du document au fomat xml, json ou pickle)
  a -- "appelle" --> c(script:get_json.py, fonction:to_json) ----> e
  a -- "appelle" --> d(script:get_pickle.py, fonction:to_pickle) ----> e

```

#### partie 4 : script `run_lda.py` - topic modeling
```mermaid
flowchart LR

  t{execute_script.sh} ----> f[run_lda.py]
  f -- "et/ou" --> g(un document resultat au format html est crÃ©Ã©)
  f -- "et/ou" --> h(les rÃ©sultats s'affichent sur le terminal)

```

### B. explication des scripts et des arguments Ã  donner Ã  chacun


#### 1. extract_corpus.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/extract_corpus.py "vers le script extract_corpus.py") 

##### les arguments

| informations          | arguments optionnels                       | arguments obligatoires | argument par dÃ©faut |
|-----------------------|--------------------------------------------|------------------------|---------------------|
| dÃ©but                 | `-s 2022-XX-XX`                            |                        | 2022-01-01          |
| fin                   | `-e 2022-XX-XX`                            |                        | 2022-12-31          |
| choix de l'analyse    | `-m spacy ou trankit ou stanza`            |                        | spacy               |
| format de sortie      | `-f xml ou json ou pickle`                 |                        | xml                 |
| chemin vers le corpus |                                            |exemple: `~/Documents/PPE2-lauracamilleshami/corpus/2022/` | |
| catÃ©gories            | exemple : `une international sport planete` |                        | toutes les catÃ©gories |

##### les fonctions qui sont appelÃ©es par ce script
- la fonction `get_Corpus()` du script `get_corpus.py`
- la fonction `to_xml()` du script `get_xml.py`
- la fonction `to_json()` du script `get_json.py`
- la fonction `to_pickle()` du script `get_pickle.py`

##### sortie
- un document structurÃ© xml, json ou pickle est crÃ©Ã©

---

#### 2. get_corpus.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/get_corpus.py "vers le script get_corpus.py")

##### les fonctions qui sont appelÃ©es par un autre script
- `get_Corpus(fichiers:Path, nom_analyse: str, categories: Optional[List[str]]=None, begin: Optional[str]=None, end: Optional[str]=None)` : renvoie une instance de la classe `Corpus`

| nom du paramÃ¨tre | type      | description                                           |
|------------------|-----------|-------------------------------------------------------|
| fichiers         | Path      | chemin vers le corpus                                 |
| nom_analyse      | str       | spacy ou trankit ou stanza                            |
| categories       | List[str] | liste des catÃ©gories choisies (optionnel)             |
| begin            | str       | dÃ©but de la pÃ©riode choisie au format ISO (optionnel) |
| end              | str       | fin de la pÃ©riode choisie au format ISO (optionnel)   |

- `get_Article(chemins:Path, cat: List[str], start_date: str, end_date: str, nom_analyse: str)` : renvoie une liste d'instances de la classe `Article`; affiche Ã©galement une barre de progression sur le terminal

| nom du paramÃ¨tre | type      | description                               |
|------------------|-----------|-------------------------------------------|
| chemins          | Path      | chemin vers le corpus                     |
| cat              | List[str] | liste des catÃ©gories choisies             |
| start_date       | str       | dÃ©but de la pÃ©riode choisie au format ISO |
| end_date         | str       | fin de la pÃ©riode choisie au format ISO   |
| nom_analyse      | str       | spacy, trankit ou stanza                  |

##### les fontions qui sont appelÃ©es par ce script
- la fonction `to_article` du script `get_articles.py`

---

#### 3. get_articles.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/get_articles.py "vers le script get_articles.py")

##### les fonctions qui sont appelÃ©es par un autre script
- `to_article(path, nom_analyse, nom_categorie, date)` : renvoie une instance de la classe `Article`

| nom du paramÃ¨tre | type | description                |
|------------------|------|----------------------------|
| path             | Path | chemin vers le fichier     |
| nom_analyse      | str  | spacy ou trankit ou stanza |
| nom_categorie    | str  | catÃ©gorie choisie          |
| date             | str  | jour choisi au format ISO |

- `which_analyse(nom_analyse, desc)` : appelle l'une des fonctions qui analyse la description de l'article et renvoie une liste d'instances de la classe `Token`

| nom du paramÃ¨tre | type | description                         |
|------------------|------|-------------------------------------|
| nom_analyse      | str  | spacy ou trankit ou stanza          |
| desc             | str  | description de l'article Ã  analyser |

##### les fontions qui sont appelÃ©es par ce script
- la fonction `get_spacy(desc)` du script `get_analyse.py` ou
- la fonction `get_trankit(desc)` du script `get_analyse.py` ou
- la fonction `get_stanza(desc)` du script `get_analyse.py`

---

#### 4. get_analyse.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/get_analyse.py "vers le script get_analyse.py")

##### les fonctions qui sont appelÃ©es par un autre script
- `get_stanza(description)` : renvoie une liste d'instances de la classe `Token` analysÃ©es avec stanza

| nom du paramÃ¨tre | type | description                         |
|------------------|------|-------------------------------------|
| description      | str  | description de l'article Ã  analyser |

- `get_trankit(description)` : renvoie une liste d'instances de la classe `Token` analysÃ©es avec trankit

| nom du paramÃ¨tre | type | description                         |
|------------------|------|-------------------------------------|
| description      | str  | description de l'article Ã  analyser |

- `get_spacy(description)` : renvoie une liste d'instances de la classe `Token` analysÃ©es avec spacy

| nom du paramÃ¨tre | type | description                         |
|------------------|------|-------------------------------------|
| description      | str  | description de l'article Ã  analyser |

---

#### 5. get_xml.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/get_xml.py "vers le script get_xml.py")

##### les fonctions qui sont appelÃ©es par un autre script
- `to_xml(corpus)` : renvoie un document structurÃ© xml

| nom du paramÃ¨tre | type       | description                                                                                    |
|------------------|------------|------------------------------------------------------------------------------------------------|
| corpus           | dataclasse | instance de la classe `Corpus` dont on trouve les attributs dans le fichier `datastructures.py` |

---

#### 6. get_json.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/get_json.py "vers le script get_json.py")

##### les fonctions qui sont appelÃ©es par un autre script
- `to_json(corpus)` : renvoie un document structurÃ© json

| nom du paramÃ¨tre | type       | description                                                                                    |
|------------------|------------|------------------------------------------------------------------------------------------------|
| corpus           | dataclasse | instance de la classe `Corpus` dont on trouve les attributs dans le fichier `datastructures.py` |

---

#### 7. get_pickle.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/get_pickle.py "vers le script get_pickle.py")

##### les fonctions qui sont appelÃ©es par un autre script
- `to_pickle(corpus)` : renvoie un document structurÃ© pickle

| nom du paramÃ¨tre | type       | description                                                                                    |
|------------------|------------|------------------------------------------------------------------------------------------------|
| corpus           | dataclasse | instance de la classe `Corpus` dont on trouve les attributs dans le fichier `datastructures.py` |

---

#### 8. datastructures.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/datastructures.py "vers le script datastructures.py")

##### les classes
- classe `Corpus`
- classe `Article`
- classe `Token`

##### sa fonction
- ce script peut Ãªtre appelÃ© par n'importe quel script python pour profiter de ses classes et de leurs attributs

---

#### 9. run_lda.py : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/run_lda.py "vers le script run_lda.py")

##### les arguments

| informations                                                      | arguments optionnels               | arguments obligatoires        | argument par dÃ©faut |
|-------------------------------------------------------------------|------------------------------------|-------------------------------|---------------------|
| chemin vers le fichier json, xml ou pickle                        |                                    | `chemin vers le fichier`      |                     |
| choix de la forme Ã  traiter : lemme ou forme du mot               | `-f` (=forme du mot) ou `-l` (=lemme)|                             |                     |
| filtre les mots en fonction de leur POS                           | `-p`                               |                           | pas de filtrage par POS |
| nombre de sujets traitÃ©s par le modÃ¨le                            | `-t int`                           |                               | 10                  |
| chemin vers le dossier oÃ¹ crÃ©er le fichier rÃ©sultat et choix nom du fichier | `-o chemin vers le fichier` |                            | pas de fichier html |
| affiche les topics et leur cohÃ©rence sur le terminal              | `-c`                               |                               | aucun affichage     |
| valeur minimale de frÃ©quence d'apparition des mots dans le corpus | `--no_below`                       |                               | 0.1                 |
| valeur maximale de frÃ©quence d'apparition des mots dans le corpus | `--no_above`                       |                               | 0.9                 |  


##### les fonctions de ce script

- `load_xml(data_file, use_form=True, use_lemma=False, use_pos=None)` : liste de documents, oÃ¹ chaque document est une liste de chaÃ®nes reprÃ©sentant les tokens sÃ©lectionnÃ©s

| nom du paramÃ¨tre | type                    | description                                                                                    |
|------------------|-------------------------|------------------------------------------------------------------------------------------------|
| data_file        | str                     | chemin vers le fichier xml                                                                     |
| use_form         | bool (False par dÃ©faut) | si `True`, utilise la forme du mot comme clÃ© dans le dictionnaire                              |
| use_lemma        | bool (True par dÃ©faut)  | si `True`, utilise le lemme du mot comme clÃ© dans le dictionnaire                          |
| use_pos          | str (None par dÃ©faut)   | si dÃ©fini, utilise la partie du discours spÃ©cifiÃ©e (par exemple, "NOUN", "VERB", "ADJ") pour filtrer les mots dans le dictionnaire |

- `load_json(data_file, use_form=True, use_lemma=False, use_pos=None)` : liste de documents, oÃ¹ chaque document est une liste de chaÃ®nes reprÃ©sentant les tokens sÃ©lectionnÃ©s

| nom du paramÃ¨tre | type       | description                                                                                                 |
|------------------|------------|-------------------------------------------------------------------------------------------------------------|
| data_file        | str        | chemin vers le fichier json                                                                                 |
| use_form         | bool (False par dÃ©faut) | si `True`, utilise la forme du mot comme clÃ© dans le dictionnaire                              |
| use_lemma        | bool (True par dÃ©faut)  | si `True`, utilise le lemme du mot comme clÃ© dans le dictionnaire                          |
| use_pos          | str (None par dÃ©faut)   | si dÃ©fini, utilise la partie du discours spÃ©cifiÃ©e (par exemple, "NOUN", "VERB", "ADJ") pour filtrer les mots dans le dictionnaire |

- `add_bigrams(docs: List[List[str]], min_count=20)` : renvoie la liste de documents en rajoutant les bigrammes et trigrammes obtenus

| nom du paramÃ¨tre | type            | description                                                                                              |
|------------------|-----------------|----------------------------------------------------------------------------------------------------------|
| docs             | list[list[str]] | liste de documents crÃ©Ã© avec l'une des fonctions `load_format`                                           |
| min_count        | int             | prend en compte les bigrammes et trigrammes qui apparaissent 20 fois ou plus  dans le corpus de document |

- `build_lda_model(docs: List[List[str]], num_topics = 10, chunksize = 2000, passes = 20, iterations = 400, eval_every = None, no_below=20, no_above=0.5)` : renvoie le corpus (reprÃ©sentation en sac de mots des documents), le dictionnaire (reprÃ©sentation sous forme de dictionnaire des documents) et le modÃ¨le entrainÃ©

| nom du paramÃ¨tre | type            | valeur par dÃ©faut |description                                                                         |
|------------------|-----------------|-------------------|------------------------------------------------------------------------------------|
| docs             | list[list[str]] |                   | liste de documents = notre corpus                                                  |
| num_topics       | int             | 10                | le nombre de sujets extraits du corpus                                             |
| chunksize        | int             | 2000              | nombre de documents utilisÃ©s dans chaque "chunk"                                   |
| passes           | int             | 20                | nombre de passages dans le corpus pendant l'entraÃ®nement                           |
| iterations       | int             | 400               | nombre maximum d'iteration sur le corpus pendant la deduction des sujets du corpus |
| eval_every       |                 | None              | frÃ©quence d'Ã©valuation du modÃ¨le pendant l'entraÃ®nement                            |
| no_below         | int             | 20                | seuil pour filtrer les mots qui apparaissent dans moins de `no_below` documents    |
| no_above         | float           | 0.5               | seuil pour filtrer les mots qui apparaissent dans plus de `no_above` du corpus     |

- `print_coherence(model, corpus)` : affiche les resultats du modÃ¨le sur le terminal

| nom du paramÃ¨tre | type                   | description                                                                                    |
|------------------|------------------------|------------------------------------------------------------------------------------------------|
| model            | gensim.models.ldamodel | le modÃ¨le lda entraÃ®nÃ©                                                                         |
| corpus           | list[list[tuple]]      | reprÃ©sentation en sac de mots des documents                                                    |

- `save_html_viz(model, corpus, dictionary, output_path)` : gÃ©nÃ¨re la visualisation ldaviz et la sauvegarde dans le fichier html indiquÃ©

| nom du paramÃ¨tre | type                      | description                                                                                    |
|------------------|---------------------------|------------------------------------------------------------------------------------------------|
| model            | gensim.models.ldamodel    | le modÃ¨le lda entraÃ®nÃ©                                                                         |
| corpus           | list[list[tuple]]         | reprÃ©sentation en sac de mots des documents                                                    |
| dictionary       | gensim.corpora.dictionary | reprÃ©sentation sous forme de dictionnaire des documents                                        |
| output_path      | str                       | chemin vers l'emplacement du fichier html incluant son nom                                     |

- `main(corpus_file:str, num_topics, output_path: Optional[str]=None, show_coherence: bool=False)`

| nom du paramÃ¨tre | type                    | description                                                                                    |
|------------------|-------------------------|------------------------------------------------------------------------------------------------|
| corpus_file      | str                     | chemin vers le fichier Ã  traiter                                                               |
| num_topics       | int                     | nombre de sujets traitÃ©s par le modÃ¨le                                                         |
| output_path      | str ou None             | chemin vers l'emplacement du fichier resultat incluant son nom                                 |
| show_coherence   | bool (False par dÃ©faut) | pour savoir s'il faut afficher les rÃ©sultats dans le terminal                                  |

##### sortie
- le script gÃ©nÃ¨re la visualisation ldaviz et la sauvegarde dans le fichier html indiquÃ© ou montre les rÃ©sultats sur le terminal

---

#### 10. execute_scripts.sh : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/main/scripts/execute_scripts.sh "vers le script execute_scripts.py")

##### le fonctionnement gÃ©nÃ©ral

```mermaid
graph TB

    x{terminal}-->|On lance le script bash| t[./execute_scripts.sh]
    t -->|Appel de la fonction extract_corpus | B[Appel du script extract_corpus.py avec les arguments]
    B --> | Initialisation de la variable input_file | C[Appel de la fonction run_lda]
    C -->|Appel du script run_lda.py avec les arguments| E[run_lda.py]
```

##### explication
Ce script Bash comporte deux fonctions qui demandent Ã  l'utilisateur des informations et exÃ©cutent des scripts Python avec ces informations comme arguments.

La premiÃ¨re fonction, *extract_corpus*, demande Ã  l'utilisateur de fournir plusieurs informations Ã  propos du corpus de texte, telles que le chemin du rÃ©pertoire contenant les fichiers corpus, la date de dÃ©but et de fin de l'analyse, l'analyseur syntaxique Ã  utiliser, le format de sortie, et les catÃ©gories Ã  retenir. Ensuite, elle stocke le chemin et le nom de fichier de sortie dans une variable nommÃ©e *input_file* et exÃ©cute le script `extract_corpus.py` en passant les options en arguments.

La deuxiÃ¨me fonction, *run_lda*, demande Ã©galement plusieurs informations Ã  l'utilisateur, telles que l'utilisation de la forme ou le lemme, le filtrage des parties du discours (POS), le nombre de topics, la gÃ©nÃ©ration de la visualisation ldaviz, l'affichage des topics et de leur cohÃ©rence, et les valeurs pour no_below et no_above. Ensuite, elle exÃ©cute le script `run_lda.py`en passant les options en arguments.

Enfin, le script appelle *extract_corpus* pour initialiser la variable input_file, puis appelle *run_lda*.

## II. Les dÃ©fis rencontrÃ©s pendant ce projet

### le travail d'Ã©quipe
Nous avons tout de suite rÃ©ussi Ã  nous rÃ©partir les diffÃ©rentes tÃ¢ches et Ã  comprendre les atouts de chacune. Si l'une d'entre nous ne comprenait pas un point du cours ou du TP, il y avait toujours quelqu'un pour prendre le temps de l'expliquer. Si nous n'Ã©tions pas d'accord sur une partie du projet, nous nous concertions jusqu'Ã  trouver une solution. C'Ã©tait agrÃ©able de pouvoir nous faire confiance et de travailler Ã  plusieurs sur un projet, de nous rÃ©partir le travail plutÃ´t que de tout faire toute seule (ce qui n'aurait pas pu Ãªtre possible de toute maniÃ¨re).
La principale difficultÃ© a Ã©tÃ© de nous passer toutes les informations sans perdre une partie en route. Cela a donnÃ© lieu Ã  quelques incomprÃ©hensions, vite rÃ©solues.

### la recherche d'informations par soi-mÃªme
Il n'a pas toujours Ã©tÃ© facile de trouver des informations sur une librairie ou sur un bug rencontrÃ© sur un script. La documentation python a pu, disons, s'avÃ©rer indigeste par moment. Cependant, cela nous a permis d'apprendre Ã  nous dÃ©brouiller par nous-mÃªme, Ã  connaÃ®tre les sites de rÃ©fÃ©rence oÃ¹ se rendre pour trouver des informations, Ã  lire ce que nous dit le terminal quand cela ne va pas.

### les difficultÃ©s rencontrÃ©es avec `git`
Nous avons certainement apprÃ©ciÃ© Ã  apprendre Ã  manipuler le git, mais Ã§a n'a pas Ã©tÃ© toujours facile. Les  **merges** en particulier ont posÃ© pas mal de problÃ¨me. Nous avons dÃ©couvert rÃ©cemment la fonctionnalitÃ© de Visual Code Ã  comparer et Ã  rÃ©soudre les conflits-aprÃ¨s-merge, mais encore faut-il Ãªtre certain de ce que l'on souhaite garder. C'est d'autant plus difficile quand une personne passe beaucoup de temps Ã  amÃ©liorer un script et un merge Ã©crase le travail fait. En tout cas, nous sommes sur la bonne voie pour avancer dans notre maÃ®trise de cet outil incontournable de collaboration.  

### les difficultÃ©s rencontrÃ©es avec `python`
Nous avons pu dÃ©couvrir, avec une joie modÃ©rÃ©e ğŸ¥², que les librairies ne sont pas toujours adaptÃ©es Ã  toute version de python. C'est comme cela que nous avons compris l'importance d'avoir un environnement pour chaque projet oÃ¹ toute modifications n'affectent pas les autres projets en cours.

## III. Quelques sujets d'analyse ...
Nous avons toutes fait tourner le script `extract_corpus.py` avec l'analyseur `spacy`, car c'est le plus performant. L'analyseur `trankit` montre beaucoup d'erreurs au niveau des lemmes pour les verbes, et `stanza` ne fonctionne pas sur nos environnements avec python 3.10. En ce qui concerne les formats de sortie pour `extract_corpus.py`, nous avons chacune travaillÃ©e avec un format diffÃ©rent : Laura avec le format xml, Camille avec le format json, et Shami avec le format pickle. Bien que cela n'ait pas de rÃ©percussion sur les rÃ©sultats du modÃ¨le, cela nous a permis de vÃ©rifier le bon fonctionnement du script `run_lda.py` pour chacun des formats.

### ThÃ¨me nÂ°1 : La prÃ©sidentielle 
    ./lda_visu/01_04_politique.html

#### fichier d'entrÃ©e : [lien](https://raw.githubusercontent.com/Araule/M1S2_projetLauraCamilleShami/page/fichiers_bruts/2022-01-01_2022-04-28.xml)

#### choix des dates : 01-01-2022 au 28-04-2022
Cette analyse porte sur la campagne prÃ©sidentielle du dÃ©but de l'annÃ©e 2022, qui signifie la fin des vacances du rÃ©veillon et la reprise des hostilitÃ©s jusqu'au 28 avril, le lendemain de la dÃ©cision du Conseil constitutionnel validant les rÃ©sultats de lâ€™Ã©lection et proclamation officielle du nouveau prÃ©sident de la RÃ©publique.

#### choix de la catÃ©gorie : politique
Le choix s'est rapidement portÃ© sur la catÃ©gorie "politique", qui est la plus logique. On retrouve des articles sur la prÃ©sidentielle dans la catÃ©gorie "une" mais ils se retrouvent noyÃ©s dans d'autres articles sans rapport avec le thÃ¨me choisi. Pour Ã©viter trop de bruit, je n'ai gardÃ© que la catÃ©gorie politique.

#### nombre d'articles : 2269 articles
Le paramÃ¨tre chunksize du modÃ¨le lda a Ã©tÃ© Ã©tabli sur le script python Ã  2269.

#### filtre des POS : NOUN, PROPN, ADJ, VERB, ADV, NUM
AprÃ¨s avoir fait tournÃ© une premiÃ¨re fois le script sans filtrer les POS et en regardant les rÃ©sultats, j'ai choisi un certain nombre de POS : les noms et les noms propres Ã©videmment, les numÃ©raux pour garder les dates (comme les journÃ©es de vote), les verbes, les adjectifs et les adverbes pour garder une cohÃ©rence dans les rÃ©sultats du modÃ¨les.

#### filtre du mot : lemme
Le filtrage par lemme a Ã©tÃ© choisi, car l'analyse avec les formes de mots rendait les rÃ©sultats moins lisibles.

#### nombre de topics : 8
J'ai commencÃ© l'analyse avec les 10 sujets par dÃ©faut, mais je trouvais que deux paires de sujets se superposaient un peu trop alors j'ai baissÃ© cette valeur Ã  8.

#### frÃ©quence min et max : valeurs par dÃ©faut
Il ne m'a pas paru nÃ©cessaire de modifier ces valeurs.

#### analyse des rÃ©sultats
Dans l'ensemble, on va revenir sur les noms des candidats Ã  la prÃ©sidentielle : "Emmanuel" "Macron", "ValÃ©rie" "PÃ©cresse", "Marine" Le "Pen". On voit Ã©galement revenir les noms des partis politiques ou leur bord politique : "droite", "extrÃªme", "Rassemblement" (en majuscule donc on peut penser qu'il se rÃ©fÃ¨re bien au parti politique) mais uniquement ceux Ã  droite.

En regardant un peu plus loin dans les sujets, on retrouve dans le sujet 6 les noms de candidats Ã  la prÃ©sidentielle : "Jean-Luc" "MÃ©lenchon", "Anne" "Hidalgo", "Christiane" "Taubira" ainsi que  des mots faisant rÃ©fÃ©rence Ã  la prÃ©sidentielle et peut-Ãªtre mÃªme Ã  la primaire populaire comme : "candidature", "vote", "janvier" (pÃ©riode du vote au jugement majoritaire de la primaire populaire), "populaire", "campagne".

On peut voir dans le sujet 2 que des articles en anglais se sont glissÃ©s dans le corpus. GrÃ¢ce Ã  une petite requÃªte xpath du fichier xml, je me suis rendu compte que Le Monde avait Ã©crit durant cette pÃ©riode 48 articles en anglais dans la catÃ©gorie politique.

On retrouve dans le sujet 7 des mots liÃ©s Ã  l'invasion de l'Ukraine. C'est assez normal, car Le Monde n'a pas uniquement parlÃ© de la campagne prÃ©sidentielle pendant cette pÃ©riode, surtout avec un sujet aussi important. Il faut rappeler que le premier tour de la prÃ©sidentielle a eu lieu le 10 avril 2022 soit environ 2 semaines aprÃ¨s l'invasion de l'Ukraine. Il est normal que l'ensemble des candidats se soient exprimÃ©s sur ce sujet-lÃ .

Enfin, on retrouve les sujets 1 et 3, trÃ¨s similaires, oÃ¹ on retrouve toujours le sujet de la prÃ©sidentielle avec les noms de parties, les noms de candidats, ainsi que des mots "invitÃ©", "meeting", "campagne", "Ã©lection", "second" "tour", "dÃ©placement", "TÃ©lÃ©visions".

---

### ThÃ¨me nÂ°2 : l'impact de l'invasion de l'Ukraine sur les publications de Le Monde
    ./lda_visu/01_02_europe.html
    ./lda_visu/02_03_europe.html

#### fichier d'entrÃ©e : [lien pour la premiÃ¨re partie](https://raw.githubusercontent.com/Araule/M1S2_projetLauraCamilleShami/page/fichiers_bruts/2022-01-24_2022-02-23.xml),  [lien pour la deuxiÃ¨me partie](https://raw.githubusercontent.com/Araule/M1S2_projetLauraCamilleShami/page/fichiers_bruts/2022-02-24_2022-03-23.xml)

#### choix des dates : 24-01-2022 au 23-02-2022 / 24-02-2022 au 23-03-2022
Le Monde est, comme l'indique son nom, un journal qui parle beaucoup de sujets internationals et la question s'est posÃ© de savoir si l'invasion de l'Ukraine par la Russie le 24 fÃ©vrier 2022 a eu un impact sur la diversitÃ© des sujets dans le journal. Tous les articles sortis un mois avant l'Ã©vasion et un mois aprÃ¨s ont Ã©tÃ© analysÃ©.

#### choix de la catÃ©gorie : international et europe
Le choix s'est d'abord portÃ© sur la catÃ©gorie internationale, mais en regardant de plus prÃ¨s, il se trouve que l'actualitÃ© europÃ©enne se trouve Ã  la fois dans la catÃ©gorie international et la catÃ©gorie europe donc j'ai dÃ©cidÃ© de garder les deux.

#### nombre d'articles : 1240 articles pour le premier fichier xml, 1080 articles pour le deuxiÃ¨me
Le paramÃ¨tre chunksize du modÃ¨le lda a Ã©tÃ© Ã©tabli sur le script python Ã  1080.

#### filtre des POS : ADJ ADV NOUN NUM PROPN VERB
AprÃ¨s avoir fait tournÃ© une premiÃ¨re fois le script sans filtrer les POS, j'ai dÃ©cidÃ© de garder les mÃªmes POS que pour le premier thÃ¨me.

#### filtre du mot : lemme
J'ai dÃ©cidÃ© de garder l'analyse par lemme, elle me parait la plus meilleure, car l'analyse que nous souhaitons faire consiste Ã  voir les sujets et les mots qui reviennent le plus. Notre analyse ne porte pas sur la diversitÃ© des formes des mots.

#### nombre de topics : 10 pour le premier, 8 pour le deuxiÃ¨me
J'ai commencÃ© les analyses avec les 10 sujets par dÃ©faut. Il m'a paru nÃ©cessaire de baisser le nombre de topics pour le deuxiÃ¨me fichier car deux topics se superposaient quasi-complÃ¨tement. J'ai baissÃ© le nombre de topics Ã  9 puis Ã  8.

#### frÃ©quence min et max : valeurs par dÃ©faut
Il ne m'a pas paru nÃ©cessaire de modifier ces valeurs.

#### analyse des rÃ©sultats
Pendant le mois avant l'invasion dÃ©clarÃ©e de la Russie, Le Monde traitait dÃ©jÃ  de ce sujet car des tensions se faisaient sentir Ã  la frontiÃ¨re entre la Russie et l'Ukraine. Cependant, on peut voir que les sujets sont assez Ã©clatÃ©s dans l'espace en deux dimensions. Le Monde nous fait sentir que la Russie est au cÅ“ur des discussions internationales et europÃ©ennes, mais l'Ukraine ne fait pas encore totalement partie du tableau. 

Le mot "Dombass" revient car pour l'instant, c'est la derniÃ¨re tentative d'invasion de la Russie et Le Monde ne peut parler que d'Ã©vÃ¨nements passÃ©s et ne va pas parler d'Ã©vÃ¨nements qui ne sont pas arrivÃ©s. On retrouve d'ailleurs le mot "dÃ©sescalade" dans les sujets 1 et 2 car c'est ce que l'on espÃ©rait encore. On retrouve les mots "menace", "crise", "tensions", "conflit"..., mais le mot "guerre" est peu prÃ©sent, et le mot "invasion" n'est pas encore lÃ .

Cependant, pendant le mois qui a suivi le dÃ©but de l'invasion de l'Ukraine par la Russie, les mots "guerre" et "offensive" ont fait leur apparition dans la liste des 30 mots les plus importants alors que le mot "crise" disparaÃ®t. On voit aussi que les topics sont beaucoup plus rapprochÃ©s sur l'espace en deux dimensions. Les mots "Ukraine", "ukrainienne", "Ukrainiens" sont prÃ©sents sur l'ensemble des sujets car le pays est, malgrÃ© lui, un membre actif de cette guerre. 

Dans le sujet 7, on retrouve les mots "gaz", "Ã©conomie", "Ã©conomique", "sanction", "soutien", "prix" qui peuvent faire rÃ©fÃ©rence aux sanctions Ã©conomiques imposÃ©es Ã  la russie, au soutien Ã  l'Ukraine, au gaz russe qui devait arriver par le gazoduc nord stream en allemagne, ou encore Ã  l'impact Ã©conomique de la guerre sur les prix de certains produits en europe... 

Le sujet 8 est assez marginalisÃ© par rapport aux autres sujets. On retrouve toujours des mots liÃ©s Ã  la crise en Ukraine, mais il s'agirait plus de mots liÃ©s Ã  l'aspect diplomatique de la guerre. On y retrouve les mots "mÃ©dias", "rÃ©seaux", "pouvoir", "politique", "mesures", "autoritÃ©s", plutÃ´t que des mots liÃ©s Ã  l'aspect guerrier de cette invasion. On y retrouve d'ailleurs la "Chine" qui ne prend pas part au conflit, mais qui s'est rangÃ©e diplomatiquement du cÃ´tÃ© de la Russie.

---

### ThÃ¨me nÂ°3: Ete (prÃ©-vacances)

    ./lda_visu/05_07_ete.html

#### fichier d'entrÃ©e : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/page/fichiers_bruts/2022-05-01_2022-07-31.pickle)


#### choix des dates : 01-05-2022 au 31-07-2022
Avec l'hypothÃ¨se de trouver des actualitÃ©s liÃ©s Ã  l'Ã©tÃ©, cette tranche m'a paru la plus pertinente pour l'Ã©tude. 

#### choix de la catÃ©gorie : voyage, culture
Curieuse de dÃ©couvrir des sujets liÃ©s au voyage, culture ( y inclus musÃ©es, films, lecture), ces deux catÃ©gories m'ont intriguÃ©e. MÃªme si nous avons d'autres rubriques qui peuvent nous donner des informations similaires. 

#### nombre d'articles : 3640
Le nombre d'articles paraÃ®t assez cohÃ©rent pour la pÃ©riode et les catÃ©gories choisies. 

#### filtre des POS : NOUN VERB 
En effet, pour une illustration adÃ©quate des sujets traitÃ©s le nom me paraÃ®t le plus important, pourquoi pas aussi les verbes pour nuancer les Ã©vÃ©nements. 

#### filtre du mot : lemme
Pas de raison particuliÃ¨re pour ce choix, j'ai alternÃ© entre les deux analyses. 

#### nombre de topics : 8
Ce nombre est assez raisonnable pour l'analyse (ainsi qu'agrÃ©able visuellement).

#### frÃ©quence min et max : valeurs par dÃ©faut
Je n'ai pas eu le temps de jouer avec ces valeurs, je les ai donc laissÃ©es telles quelles.

#### analyse des rÃ©sultats

Pour les premiers topics nous avons Â« histoire Â», Â« chrÃ©tien Â», Â« quartier Â», Â« historique Â», Â« hÃ©ritage Â». Evidemment, nous sommes en prÃ©sence des termes liÃ©s Ã  la culture. Mais, comme attendus, nous trouvons Â« chanteur Â», Â« concert Â» , Â« cinÃ©ma Â», Â« pays Â», Â« photographe Â». Topic quatre fait rÃ©fÃ©rences aux Â« touriste Â» et Â« ande Â» (les vacances sont dans l'air).

MÃªme si les topics du milieu font allusion Ã  Â« procureur Â», Â« donald  Â», Â« population  Â», Â« quotidien Â», nous revenons vers  Â« cinÃ©aste Â», Â« lecture Â», Â« exposition  Â»,  Â« dimanche Â» et Â« voyage Â».

---

### ThÃ¨me nÂ°4: En vacances 

    ./lda_visu/07_08_international.html

#### fichier d'entrÃ©e : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/page/fichiers_bruts/2022-07-01_2022-08-31.pickle)


#### choix des dates : 01-07-2022 au 31-08-2022

#### choix de la catÃ©gorie : international


#### filtre des POS : ADJ NOUN VERB 
Encore une fois, le nom est, selon moi, l'aspet le plus important pour l'analyse. ExpÃ©rimenter avec les autres peut enrichir l'Ã©tude. 

#### filtre du mot : forme
Pas de raison particuliÃ¨re pour ce choix, j'ai alternÃ© entre les deux analyses. Je pense avoir une prÃ©fÃ©rence pour celle-ci. 

#### nombre de topics : 6
Pour 2 mois, 6 topics semblent Ãªtre le bon choix. 


#### frÃ©quence min et max : valeurs par dÃ©faut
Je n'ai pas eu le temps d'expÃ©rimenter avec ces valeurs. 


#### analyse des rÃ©sultats
Je me suis lancÃ©e dans ces choix de dates et catÃ©gories en espÃ©rant trouver des choses plus exotiques, mais l'atmosphÃ¨re semble Ãªtre plus tendue. Les mentions de Â« russe Â» , Â« guerre Â», Â« ministre Â», Â« tribune Â», Â« mort Â» , Â« tribune  Â» , Â« Ã‰tats-unis Â» nous renvoie Ã  la situation compliquÃ©e Ã  l'international de cette Ã©poque. 

Le topic 3 dÃ©picte plus prÃ©cisÃ©ment la pÃ©riode, avec la prÃ©sence des termes comme Â« ukrainien Â»,  Â« Ã‰tats-unis Â» , Â« annoncÃ© Â», Â« attaque Â», Â« enquÃªte Â», Â« journaliste Â» , Â« neuclÃ©aire Â». La prÃ©sence de Â« gaz Â» et Â« neuclÃ©aire  Â» nous laisse deviner le contexte de Â« neuclÃ©aire  Â», si on fait allusion Ã  la source de l'Ã©nergie ou une guerre potentielle ...

---

### ThÃ¨me nÂ°5 : La rentrÃ©e

    ./lda_visu/09_10_societe.html

#### fichier d'entrÃ©e : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/page/fichiers_bruts/2022-09-01_2022-10-30.json)

#### choix des dates : 01-09-2022 au 30-10-2022
Cette analyse porte sur la pÃ©riode commenÃ§ant le 01-09-2022 et se terminant le 30-10-2022. Nous avons trouvÃ© cette pÃ©riode intÃ©ressante, car il s'agit de la pÃ©riode de la rentrÃ©e et elle entraÃ®ne souvent des changements.

#### choix de la catÃ©gorie : societe
Jâ€™avais dâ€™abord choisi la catÃ©gorie â€œactualite-mediasâ€ mais aprÃ¨s la visualisation lda ne me semblait aussi pertinente que voulu pour montrer les changements qui sâ€™effectuent lors de la rentrÃ©e. J'ai donc dÃ©cidÃ© de prendre la catÃ©gorie "societe", car elle me semblait parfaite pour illustrer les changements dans le pays.

#### nombre d'articles : 1100
Le module tqdm ajoutÃ© dans get_corpus.py dans la fonction get_Article affiche avoir traitÃ© un total de 1100 articles.

#### filtre des POS : NOUN VERB
J'ai d'abord filtrÃ© sur toutes les parties du discours(POS) puis en fonction de mes observations et de mes conclusions j'affinais le filtre en sÃ©lectionnant les POS appropriÃ©s. Jâ€™ai dÃ©cidÃ© de mâ€™arrÃªter aux noms pour observer les thÃ¨mes abordÃ©s et les verbes pour voir ceux quâ€™on utilisait dans ce type dâ€™article visant Ã  la fois Ã  informer et Ã  dÃ©noncer ce qui se passe dans la sociÃ©tÃ©. Jâ€™avais au dÃ©part ajouter les noms propres, mais mis Ã  part â€œFranceâ€ rien de pertinent, je lâ€™ai donc retirÃ©.

#### filtre du mot : lemme
Le filtrage par lemme a Ã©tÃ© choisi, car l'analyse avec les formes de mots rendait les rÃ©sultats moins lisibles.

#### nombre de topics : 8
J'ai commencÃ© l'analyse avec les 10 sujets par dÃ©faut mais en rÃ©duisant Ã  8 cela mâ€™a semblÃ© moins redondant au niveau des topics.

#### frÃ©quence min et max : valeurs par dÃ©faut
Il ne m'a pas paru nÃ©cessaire de modifier ces valeurs.

#### analyse des rÃ©sultats
AprÃ¨s avoir filtrÃ© avec tous les POS, on remarque l'emploi du vocabulaire liÃ© Ã  la lÃ©gislation comme "tribune", "ministre", "justice" ou encore "mesure" qui fait sens au vu de la pÃ©riode. Les mots dans le topic 1, on remarque que l'emploi du vocabulaire de la justice voire pÃ©nitencier est particuliÃ¨rement prÃ©sent comme "condamner", "enquÃªte" ou â€œviolenceâ€. Alors que dans le topic 3, on remarque que les thÃ¨mes abordÃ©s sont plus variÃ©s, synonyme de cette pÃ©riode de changement. On y observe â€œsantÃ©â€, â€œÃ©ducationâ€ ou encore â€œdroitâ€.

Je me suis intÃ©ressÃ©e ensuite Ã  quels verbes Ã©taient utilisÃ©s sachant qu'il s'agit d'articles visant Ã  un informer, j'ai donc filtrÃ© par verbe. Je m'attendais Ã  des verbes dÃ©monstratifs, mais il s'est plutÃ´t avÃ©rÃ© Ãªtre des verbes d'action, de modalitÃ© comme "annoncer", "devoir", "publier", "mettre", "accuser", "condamner" ou encore "prendre", qui en effet prennent sens, car ces articles visent au final Ã  informer, responsabiliser, Ã©valuer et expliquer divers aspects de la sociÃ©tÃ©.

Le mot "femme" qui est apparaissant Ã  la cinquiÃ¨me position dans le top des trente mots les plus occurrents mâ€™a intriguÃ©. J'ai donc filtrÃ© par nom pour voir quels termes et thÃ¨mes pouvaient Ãªtre liÃ©s aux femmes. Il Ã©tait particuliÃ¨rement prÃ©sent dans le cinquiÃ¨me topic oÃ¹ on remarque que c'est plutÃ´t la place de la femme dans la sociÃ©tÃ© qui est abordÃ©e avec le vocabulaire :"travail", "parole", "condition", et "mouvement", bien quâ€™on observe tristement le mot â€œviolenceâ€ juste aprÃ¨s â€œfemmeâ€. Cette question de la place de la femme dans la sociÃ©tÃ© est toujours prÃ©sente, mais j'Ã©mets la supposition qu'elle a dÃ» refaire surface plus vivement suite Ã  l'arrestation violente d'une femme en Iran qui a entraÃ®nÃ© sa mort pour cause de "port de vÃªtement non appropriÃ©" Ã  cette mÃªme pÃ©riode.

---

### ThÃ¨me nÂ°6 : La Coupe du monde de foot

    ./lda_visu/10_12_sport.html

#### fichier d'entrÃ©e : [lien](https://github.com/Araule/M1S2_projetLauraCamilleShami/blob/page/fichiers_bruts/2022-10-01_2022-12-30.json)

#### choix des dates : 01-10-2022 au 30-12-2022
La seconde analyse commence Ã  partir du 01-10-2022 et se termine le 30-12-2022. Nous nous sommes intÃ©ressÃ©es Ã  cette pÃ©riode, car il y a eu le mondial de foot qui s'y est dÃ©roulÃ©. 

#### choix de la catÃ©gorie : sport
C'est donc avec une certaine Ã©vidence que jâ€™ai choisi la catÃ©gorie sport.

#### nombre d'articles : 1760
Le module tqdm ajoutÃ© dans get_corpus.py dans la fonction get_Article affiche avoir traitÃ© un total de 1760  articles.

#### filtre des POS : NOUN, PROPN, NUM
Comme pour le thÃ¨me 5, j'ai d'abord fait une premiÃ¨re analyse avec tous les POS puis affinÃ© par la suite. j'ai choisi un certain nombre de POS : les noms et les noms propres Ã©videmment pour le pays dans lequel elle sâ€™est dÃ©roulÃ© ainsi que le nom des joueurs et les numÃ©raux pour les les scores et plus particuliÃ¨rement les buts, le nombre de match etc.

#### filtre du mot : lemme
Le filtrage par lemme a Ã©tÃ© choisi, car l'analyse avec les formes de mots rendait les rÃ©sultats moins lisibles.

#### nombre de topics : 8
J'ai commencÃ© l'analyse avec les 10 sujets par dÃ©faut, mais en rÃ©duisant Ã  8 cela mâ€™a semblÃ© plus cohÃ©rent au niveau de la frÃ©quence mots et des topics.

#### frÃ©quence min et max : valeurs par dÃ©faut
Il ne m'a pas paru nÃ©cessaire de modifier ces valeurs.

#### analyse des rÃ©sultats
Avec tous les POS, les cinq mots les plus frÃ©quents sont "coupe", "monde", "sport", "1", "0" et "2". En ce qui concerne le topic 1, les cinq mots les plus frÃ©quents sont "2", "1", "0", "monde", "finale", "finale". On observe qu'il y a beaucoup de chiffres ce qui paraÃ®t logique. A cela sâ€™ajoute du vocabulaire liÃ© particuliÃ¨rement au foot comme "coupe", "final", "joueur", "qualification",â€tirâ€, "ballon", etc. 

Contrairement Ã  ce que je pensais, il y a Ã  premiÃ¨re vue peu d'adjectif. J'ai donc filtrÃ© par adjectif et effectivement, il y en a peu. Soit il y en a qui ne sont pas en rapport avec le sport, mais semble plutÃ´t liÃ© au joueur comme "sexuel", soit ils ne sont pas en rapport avec le foot, comme "olympique" ou "paralympique".

Il m'a semblÃ© sensÃ© de finir par filtrer Ã  la fois par nom, pour le vocabulaire liÃ© au sport, les noms propres, pour les joueurs connus et les pays et enfin par les chiffres a vu de leur grande prÃ©sence dans l'analyse de base. Et effectivement, les chiffres sont bien une caractÃ©ristique du genre d'article sportif pour annoncer les scores, le classement de l'Ã©quipe par exemple. Les chiffres sont souvent suivis des termes "match", "but" ou encore "groupe".

## IV. En savoir plus

Ces fichiers markdown a Ã©tÃ© crÃ©Ã© pour la rÃ©alisation du projet *BoÃ®tes Ã  outils* du cours Programmation et Projet EncadrÃ© 2 en Master Traitement Automatique des Langues.

Nous sommes trois Ã©tudiantes en premiÃ¨re annÃ©e de Master TAL Ã  l'Inalco.

<img src="./image/laura.jpg" width=100px> &nbsp; &nbsp; **Laura Darenne**
> Bonjour ! Je suis Laura, diplÃ´mÃ©e en licence LLCER chinois Ã  l'Inalco et maintenant en master TAL toujours Ã  l'Inalco. Ce deuxiÃ¨me projet n'a pas toujours Ã©tÃ© facile mais Ã§a a Ã©tÃ© un plaisir de travailler en Ã©quipe avec Camille et Shami. Le courant est si bien passÃ© ! J'espÃ¨re que vous avez apprÃ©ciÃ© cette prÃ©sentation markdown. C'est un peu mon petit bÃ©bÃ©, et ma partie prÃ©fÃ©rÃ©e chaque semestre ...

<br>

<img src="./image/camille.jpg" width=100px> &nbsp; &nbsp; **Camille Clavier**
> Bonjour ! FraÃ®chement diplÃ´mÃ©e d'une licence de civilisation corÃ©enne avec comme spÃ©cialitÃ© littÃ©rature, art et traduction, j'ai trouvÃ© ce projet assez intÃ©ressant car on y travaille plus l'aspect linguistique ! 
J'ai trouvÃ© que travaillÃ© sur diffÃ©rents formats et nous laissÃ© le choix Ã©tait aussi bien une difficultÃ©, qu'une opportunitÃ© de pouvoir s'exercer donc il y a eu des hauts et des bas mais on s'en sort toujours haha ! 

<br>

<img src="./image/shami.jpg" width=100px> &nbsp; &nbsp; **Shami Thirion Sen**
> Hola! AprÃ¨s un parcours acadÃ©mique et professionnel linguistique, l'envie de renouer avec la logique est l'informatique m'a amenÃ©e Ã  rejoindre le Master en TAL. Ce deuxiÃ¨me projet de l'annÃ©e, premier avec l'Ã©quipe (charmant :) actuel, je dÃ©couvre les diffÃ©rents aspects du TAL, Ã  travers des fonctionalitÃ©s Python pour la lecture, l'analyse et la prÃ©sentations des donnÃ©es. 
Projet trÃ¨s enrichissant (et nÃ©cessaire) pour apprendre le travail en Ã©quipe. 
